<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="BSc Geography" />


<title>Introduction to Remote Sensing</title>
<!-- Material Design fonts -->
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/icon?family=Material+Icons">
<script src="index_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.7/css/bootstrap.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.7/js/bootstrap.min.js"></script>
<script src="index_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<script src="index_files/navigation-1.1/tabsets.js"></script>
<script src="index_files/navigation-1.1/codefolding.js"></script>
<link href="index_files/magnific-popup-1.1.0/magnific-popup.css" rel="stylesheet" />
<script src="index_files/magnific-popup-1.1.0/jquery.magnific-popup.min.js"></script>
<link href="index_files/bootstrap_material-0.1/bootstrap-material-design.min.css" rel="stylesheet" />
<link href="index_files/bootstrap_material-0.1/ripples.min.css" rel="stylesheet" />
<script src="index_files/bootstrap_material-0.1/material.min.js"></script>
<script src="index_files/bootstrap_material-0.1/ripples.min.js"></script>
<link href="index_files/material-0.1/material.css" rel="stylesheet" />
<script src="index_files/material-0.1/material.js"></script>
<script src="index_files/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="material_adjust_blue.css" type="text/css" />

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("toc");
});
</script>

<!-- code folding -->

</head>

<body>

<div class="header-panel shadow z-2">
    <div class="container-fluid">
        <div class="row">
            <div class="col-xs-3">
        <div id="header">
    <h1 class="title">Introduction to Remote Sensing</h1>
                <h4 class="author">BSc Geography</h4>
                <h4 class="date">Winter term 2020/2021</h4>
        </div>
    </div>
</div>
</div>
</div>


<div class="container-fluid main-container">
    <div class="row">
      <nav class="col-xs-3 menu">
        <div id="toc">
        <ul>
        <li><a href="#welcome">Welcome!</a></li>
        <li><a href="#course-materials">Course materials</a></li>
        <li><a href="#visual-image-interpretation">Visual image interpretation</a></li>
        <li><a href="#on-screen-visualization">On-screen visualization</a></li>
        <li><a href="#land-cover-land-use-classification">Land cover / land use classification</a></li>
        <li><a href="#lab-and-field-spectroscopy">Lab and field spectroscopy</a></li>
        <li><a href="#optical-data-multi--hyperspectral">Optical data (Multi- / Hyperspectral)</a></li>
        <li><a href="#enmap-box-for-qgis">EnMAP Box for QGIS</a></li>
        <li><a href="#data-acquisition">Data acquisition</a></li>
        <li><a href="#vegetation-properties-spectral-indices">Vegetation properties &amp; spectral indices</a></li>
        <li><a href="#image-classification">Image classification</a></li>
        <li><a href="#random-forest">Random forest</a></li>
        <li><a href="#accuracy-assessment">Accuracy assessment</a></li>
        <li><a href="#sentinel-2-time-series">Sentinel-2 time series</a></li>
        <li><a href="#modis-time-series">MODIS time series</a></li>
        <li><a href="#case-studies-change-detection">Case studies: Change detection</a></li>
        </ul>
        </div>
        
        
        
      </nav>
     <div class="pages col-xs-9">
     <div class="row">
       <div class="col-xs-10">



<div id="welcome" class="section level1">
<h1>Welcome!</h1>
<div class="figure">
<img src="fig/EO_header.PNG" alt="" />
<p class="caption">EOL Logo</p>
</div>
<div id="about" class="section level2">
<h2>About</h2>
<p>Introduction to Remote Sensing is an introductory remote sensing course for Geography students at Humboldt-Universität zu Berlin. In this course, you will be exposed to theoretical fundaments and introductory applications of remote sensing. The course is based on open source software.</p>
<hr />
</div>
<div id="requirements" class="section level2">
<h2>Requirements</h2>
<hr />
</div>
<div id="learning-goals-course-contents" class="section level2">
<h2>Learning goals &amp; course contents</h2>
<hr />
</div>
</div>
<div id="course-materials" class="section level1">
<h1>Course materials</h1>
<div id="software" class="section level2">
<h2>Software</h2>
<p>We use openly available and platform independent (Windows, Linux, Mac OS) software packages throughout this course. Please install the latest versions of:</p>
<ul>
<li><a href="https://www.r-project.org/">R v3.6.X</a></li>
<li><a href="https://rstudio.com/products/rstudio/">R studio v1.2.X</a></li>
<li><a href="https://www.qgis.org/">QGIS v3.1X.X</a></li>
</ul>
<hr />
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<hr />
</div>
<div id="assignments" class="section level2">
<h2>Assignments</h2>
<p>The weekly assignments are defined in the respective session. Each session comprises several tasks that involve scipting in R. Course participants must submit completed assignments, documented as R scripts, in <a href="http://moodle.hu-berlin.de/">moodle</a> to pass. Weekly submission deadlines are monday, 23:59. Please name the script of your work group as SXX_name1_name2.R. Please structure your script for every assignment as follows:</p>
<hr />
</div>
</div>
<div id="visual-image-interpretation" class="section level1">
<h1>Visual image interpretation</h1>
<div class="figure">
<img src="fig/Berlin_2009.png" alt="" />
<p class="caption">Berlin from above in Google Earth<sup>TM</sup>, 2009</p>
</div>
<div class="figure">
<img src="fig/Berlin_2019.png" alt="" />
<p class="caption">Berlin from above in Google Earth<sup>TM</sup>, 2019</p>
</div>
<div id="image-interpretation" class="section level2">
<h2>Image interpretation</h2>
<ul>
<li><p>Open Google Earth<sup>TM</sup></p></li>
<li><p>Deactivate the oblique view (use key “R”)</p></li>
<li><p>Disable multimedia (e.g. pictures)</p></li>
<li><p>Move to two different positions in Berlin and answer the following questions with help of the aerial photographs:</p>
<ul>
<li><p>Which season was the flight operated in?</p></li>
<li><p>Is it possible to get the exact month and/or day?</p></li>
<li><p>What was the day of the week?</p></li>
<li><p>What was the time of day?</p></li>
</ul></li>
</ul>
</div>
<div id="digitizing" class="section level2">
<h2>Digitizing</h2>
<ul>
<li><p>Navigate to Campus Adlershof</p></li>
<li><p>Right-click on ‘Meine Orte’ and create a new folder called ‘FE1’</p></li>
<li><p>Use the digitizing tools (see image below) to…</p>
<ul>
<li><p>Mark the wind tunnel as a point</p></li>
<li><p>Digitize a section of the S-Bahn trail as a line</p></li>
<li><p>Save the Institute of Geography as a polygon (semitransparent and outlined)</p></li>
</ul></li>
<li><p>The results of the digitization need to be located in the ‘FE1’ folder</p></li>
<li><p>Save the folder ‘FE1’ with a right-click on the folder as a .kmz file on O:/…</p>
<div class="figure">
<img src="fig/digitizing_tools.png" alt="" />
<p class="caption">Digitizing tools</p>
</div></li>
</ul>
</div>
<div id="observing-change" class="section level2">
<h2>Observing change</h2>
<ul>
<li><p>Use the date tool (see image below) to observe older/historical photos of Adlershof and answer the following questions:</p>
<ul>
<li><p>What is the frequency of photo observations before and after 2010?</p></li>
<li><p>What major changes can be detected in Adlershof in 2000, 2010 and 2019?</p></li>
<li><p>Do your polygons/lines/points fit older pictures as well?</p></li>
<li><p>Describe the differences of image data in 1953, 2000 and 2019. Why do they differ?</p></li>
</ul>
<div class="figure">
<img src="fig/datumstool.png" alt="" />
<p class="caption">Date tool</p>
</div></li>
</ul>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<ul>
<li><p>The analysis of earth observation data (satellite and aerial images) allows us to draw a variety of conclusions about processes and conditions of the Earth’s surface. For such analysis, different image properties are used (object features and context).</p></li>
<li><p>With help of image data from different dates, changes of the Earth’s surface can be analyzed.</p></li>
<li><p>The quality of image data enhanced over time. Today, satellite images with a spatial resolution of less than 1 m are available for most parts of the earth, in urban agglomerations aerial photographs often even exceed 10 cm spatial resolution.</p></li>
</ul>
</div>
<div id="exercise" class="section level2">
<h2>Exercise</h2>
<p>Characterize the land cover and land use change in Berlin with Google Earth<sup>TM</sup>.</p>
<ul>
<li><p>On O:/WS2021_FE1/S01 you find a .kmz file with two given areas (Berlin-Mitte and Berlin-Adlershof)</p></li>
<li><p>Choose three suitable objects within each area and outline them with the digitizing tools</p></li>
<li><p>Choose three time steps (depending on the available data) that show a change process for your chosen objects</p></li>
<li><p>Answer the following questions for your objects (with images and text):</p>
<ul>
<li><p>What changes contentwise?</p></li>
<li><p>What changes concretely in the photos?</p></li>
</ul></li>
</ul>
<p><em>Upload your results as a PDF file on Moodle (each participant separately).</em></p>
<hr />
</div>
</div>
<div id="on-screen-visualization" class="section level1">
<h1>On-screen visualization</h1>
<div id="recap" class="section level2">
<h2>Recap</h2>
<ul>
<li><p>We can describe the human eye as a ‘sensor with three bands’</p></li>
<li><p>Sensitive for electromagnetic radiation (EMR) in the blue, green and red regions: <strong>spectral range</strong> between ~400-700 nm</p></li>
<li><p>The receptors for the three colors are stimulated across wavelength regions of ~150-200 nm (<strong>spectral resolution</strong>)</p></li>
<li><p>The intervals between the wavelengths of maximum sensitivity are ~50 nm to 150 nm wide (<strong>spectral sampling interval</strong>)</p></li>
</ul>
<div class="figure">
<img src="fig/retinal%20response.png" alt="" />
<p class="caption">Retinal response of the human eye (Source: <a href="http://www.planetary.org/rrgtm/emspectrum.html">planetary.org LINK ÜBERPRÜFEN!</a> )</p>
</div>
<ul>
<li>Digital cameras correspond to imaging sensors with three bands</li>
</ul>
<div class="figure">
<img src="fig/red-green-blue.png" alt="" />
<p class="caption">Red-green-blue representation</p>
</div>
<ul>
<li><p>Spectrometers are sensitive to wavelengths beyond the human eye’s sensitivity</p></li>
<li><p><strong>Optical remote sensing</strong> makes use of the visible light (~380 - 700 nm), and the near and short-wave infrared (0.7 - ~3 µm)</p></li>
<li><p><strong>Thermal remote sensing</strong> detects thermal infrared radiation (5 - 15 µm)</p></li>
<li><p><strong>Radar remote sensing</strong> detects microwave radiation (1 mm - 1 m)</p></li>
<li><p>Common abbrevations:</p>
<ul>
<li><p>VIS = visible: 380 - 700 nm</p></li>
<li><p>nIR = near infrared: 0.7 - 1.3 µm</p></li>
<li><p>swIR = short wave infrared: 1.3 - 3 µm</p></li>
<li><p>tIR = thermal infrared: 5 - 15 µm</p></li>
</ul></li>
</ul>
<div class="figure">
<img src="fig/wavelength%20regions.jpg" alt="" />
<p class="caption">Wavelength regions (Source: <a href="http://www.arm.gov/news/facility/post/5946">arm.gov LINK ÜBERPRÜFEN!</a>)</p>
</div>
<ul>
<li>Optical remote sensing sensors make it possible to take images in the visible light (VIS), near-infrared (nIR) and shortwave-infrared (swIR)</li>
</ul>
<div class="figure">
<img src="fig/Bild%20sichtbares%20Licht.png" alt="" />
<p class="caption">Image showing the reflection of the visible light</p>
</div>
<div class="figure">
<img src="fig/Bild%20nir%20swir.png" alt="" />
<p class="caption">Image showing the reflection of the near-infrared and visible light</p>
</div>
</div>
<div id="additive-color-model" class="section level2">
<h2>Additive color model</h2>
<ul>
<li><p>Primary colours: red, green and blue (RGB)</p></li>
<li><p>Values range from 0 to 255 (the higher the more intense)</p></li>
<li><p>Max. 256 * 256 * 256 = 16,7 mio colours</p></li>
<li><p>Complementary/secondary colours: cyan, magenta and yellow (CMY)</p></li>
</ul>
<div class="figure">
<img src="fig/RGB%20Farbmodell.png" alt="" />
<p class="caption">RGB color model (Source left: <a href="http://www.orange-sinne.de/additives_farbmodell.html">orange-sinne.de</a>, source right: <a href="http://www.informatikzentrale.de">informatikzentrale.de</a>)</p>
</div>
<div id="exercise-for-colour-mixing-in-qgis" class="section level3">
<h3>Exercise for colour mixing in QGIS</h3>
<ul>
<li><p>Open the shapefile ‘charlottenburg_point.shp’ in a new QGIS-project</p></li>
<li><p>Open the ‘Select Color Tool’ of the shapefile (Properties &gt; Symbology &gt; double click on colour bar)</p></li>
<li><p>For displaying different colours QGIS offers the RGB and HSV colour model</p></li>
</ul>
<div class="figure">
<img src="fig/RGB%20QGIS.png" alt="" />
<p class="caption">Select Color Tool in QGIS</p>
</div>
<ul>
<li>Enter the colour values of the following table in the QGIS colour model and note/describe the resulting colour</li>
</ul>
<div class="figure">
<img src="fig/tabelle%20rgb.jpg" alt="" />
<p class="caption">Table with colour values</p>
</div>
</div>
</div>
<div id="screen-representation-of-remote-sensing-images" class="section level2">
<h2>Screen representation of remote sensing images</h2>
<ul>
<li>Remote sensing images can be presented as a greyscale image (single band) or RGB-composite (combination of three different bands)</li>
</ul>
<div class="figure">
<img src="fig/rgb%20fe%20bilder.png" alt="" />
<p class="caption">Satellite images as single band grey, RGB-composite (true colour), RGB-composite (false colour)</p>
</div>
</div>
<div id="image-histogram" class="section level2">
<h2>Image histogram</h2>
<ul>
<li>Image histograms show the frequency distribution of pixel values i.e. of a single band</li>
</ul>
<div class="figure">
<img src="fig/histogramm%201.png" alt="" />
<p class="caption">Band 3 (red) as a greyscale image and its image histogram</p>
</div>
<div id="contrast-stretch" class="section level3">
<h3>Contrast stretch</h3>
<ul>
<li><p>Every RGB-channel has a colour depth of 8-bit on a monitor (equivalent to 256 greyscales)</p></li>
<li><p>Transfer of pixel values of an image (or band) to a monitor initially 1:1</p></li>
<li><p>At best, full grey value range is utilized optimally</p></li>
</ul>
<div class="figure">
<img src="fig/histogramm%202.png" alt="" />
<p class="caption">Image histogram and satellite image with an optimally utilized grey value range</p>
</div>
<ul>
<li><p>Due to recording and sensor conditions, data sets (or bands) often display only a section of the 256 obtainable grey values</p></li>
<li><p>With a 1:1 transfer, images are often low-contrast</p></li>
</ul>
<div class="figure">
<img src="fig/histogramm%203.png" alt="" />
<p class="caption">Image histogram and satellite image with low-contrast</p>
</div>
<ul>
<li><p>“Stretching” the image histogram, the screen display can be enhanced</p></li>
<li><p>Caution! The screen display changes, the data stays the same!</p></li>
</ul>
<div class="figure">
<img src="fig/histogramm%204.png" alt="" />
<p class="caption">Stretching of an image histogram</p>
</div>
<ul>
<li><p>Contrast enhancement describes a function of representation that is used to transfer pixel values in grey values</p></li>
<li><p>Often, linear contrast enhancement is used where the increase in gray value per increase in pixel value remains the same for the relevant value ranges</p></li>
</ul>
<div class="figure">
<img src="fig/histogramm%205.png" alt="" />
<p class="caption">Min-max linear contrast stretch and standard deviation linear contrast stretch (Source: Jensen, 2011)</p>
</div>
</div>
</div>
<div id="exercise-1" class="section level2">
<h2>Exercise</h2>
<ul>
<li><p>Open the Sentinel-2 image ‘20150704_LEVEL2_SEN2A_BOA_berlin.bsq’ in QGIS</p></li>
<li><p>The image has a spatial resolution of 10 m, an extent of 2700 x 2700 pixel and 4 spectral bands (B1 = blue, B2 = green, B3 = red, B4 = nIR)</p></li>
<li><p>Open the display options of the image (Symbology)</p></li>
<li><p>What are the default settings after loading the image:</p>
<ul>
<li><p>render type</p></li>
<li><p>RGB assignment</p></li>
<li><p>min/max value settings</p></li>
</ul></li>
</ul>
<div class="figure">
<img src="fig/bildschirmdarstellung%20qgis.png" alt="" />
<p class="caption">Layer properties &gt; Symbology in QGIS</p>
</div>
<ul>
<li>Display the Sentinel-2 image in true colours</li>
</ul>
<div class="figure">
<img src="fig/sen2%20echtfarben.png" alt="" />
<p class="caption">Sentinel-2 image in true colours</p>
</div>
<ul>
<li><p>Now, display only band 1 (blue) in greyscale (Render type &gt; Singleband grey)</p>
<ul>
<li><p>How did the min/max value settings change?</p></li>
<li><p>How rich in contrast does the image appear?</p></li>
<li><p>How does the image representation change when you alter the min/max value settings (i.e. cumulative count cut, etc.)?</p></li>
</ul></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Switch to the histogram section and calculate the image histogram</p></li>
<li><p>Adjust the settings as shown in the picture below</p></li>
<li><p>Select the nIR band</p></li>
<li><p>Vary the settings for min/max values to alter the contrast manually</p></li>
<li><p>Try to differentiate water bodies from land mass by stretching the min/max values</p></li>
</ol>
<div class="figure">
<img src="fig/bildschirmdarstellung%20qgis%202.png" alt="" />
<p class="caption">Settings for image histogram</p>
</div>
<ol style="list-style-type: decimal">
<li><p>Create a true and false colour (R = nIR, G = red, B = green) representation of the Sentinel 2 image and describe the main differences (key words)</p></li>
<li><p>Find one example (Screenshot) for each of the following surfaces with the true and false colour representation:</p>
<ul>
<li><p>Deciduous forest</p></li>
<li><p>Coniferous forest</p></li>
<li><p>Artificial turf pitch</p></li>
<li><p>True turf pitch</p></li>
</ul></li>
<li><p>Subsequently, describe the differences between deciduous and coniferous forest and artificial and true turf</p></li>
<li><p>For what phenomenons and/or surfaces is the nIR channel particularly sensitive?</p></li>
</ol>
<p><em>Summarize task 1 - 4 visually and textually and upload your results as a PDF file on Moodle.</em></p>
<hr />
</div>
</div>
<div id="land-cover-land-use-classification" class="section level1">
<h1>Land cover / land use classification</h1>
<div id="mapping-the-earth-surface" class="section level2">
<h2>Mapping the Earth surface</h2>
</div>
<div id="land-cover-or-land-use" class="section level2">
<h2>Land cover or land use?</h2>
</div>
<div id="visual-image-interpretation-1" class="section level2">
<h2>Visual image interpretation</h2>
</div>
<div id="land-use-cover-area-frame-survey-lucas" class="section level2">
<h2>Land use / cover area frame survey (LUCAS)</h2>
</div>
<div id="exercise-2" class="section level2">
<h2>Exercise</h2>
<hr />
</div>
</div>
<div id="lab-and-field-spectroscopy" class="section level1">
<h1>Lab and field spectroscopy</h1>
<div id="usgs-spectral-characteristics-viewer" class="section level2">
<h2><a href="https://landsat.usgs.gov/spectral-characteristics-viewer">USGS spectral characteristics viewer</a></h2>
</div>
<div id="section" class="section level2">
<h2></h2>
<hr />
</div>
</div>
<div id="optical-data-multi--hyperspectral" class="section level1">
<h1>Optical data (Multi- / Hyperspectral)</h1>
<div id="raster-formats" class="section level2">
<h2>Raster formats</h2>
</div>
<div id="metadata" class="section level2">
<h2>Metadata</h2>
</div>
<div id="hymap-data" class="section level2">
<h2>HyMap data</h2>
<hr />
</div>
</div>
<div id="enmap-box-for-qgis" class="section level1">
<h1>EnMAP Box for QGIS</h1>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
</div>
<div id="key-features" class="section level2">
<h2>Key features</h2>
</div>
<div id="demo" class="section level2">
<h2>Demo</h2>
<hr />
</div>
</div>
<div id="data-acquisition" class="section level1">
<h1>Data acquisition</h1>
<div id="provider-vielleicht-eher-sentinel-2" class="section level2">
<h2>Provider (vielleicht eher ‘Sentinel 2’?)</h2>
<ul>
<li><p>COPERNICUS program features a pair of optical Earth observing satellites: Sentinel-2A and -2B Launched in June 2015 (Sentinel-2A), and March 2017 (Sentinel-2B)</p></li>
<li><p>Revisit time 5 days with both satellites, 290km swath width</p></li>
<li><p>Sensor: Multispectral Imager (MSI), 13 spectral bands, partly resembling Landsat</p></li>
<li><p>Spatial resolution of 10 – 60 m, depending on spectral bands, e.g. nIR bands 8 (10m) and 8a (20m).</p></li>
</ul>
<div class="figure">
<img src="fig/Sentinel2_bands.png" alt="" />
<p class="caption">Sentinel 2 vs Landsat 7 and 8</p>
</div>
</div>
<div id="sentinel-2" class="section level2">
<h2>Sentinel 2</h2>
<ul>
<li><p>Sentinel-2 products are delivered in various processing levels.</p>
<ul>
<li><p>Level 1B: Top-of-atmosphere radiance values in sensor geometry</p></li>
<li><p>Level 1C: Top-of-atmosphere reflectance in cartographic geometry</p></li>
<li><p>Level 2A: Bottom-of-atmosphere reflectance in cartographic geometry</p></li>
</ul></li>
<li><p>L1C and L2A products are partitioned in “granules”: 100x100 km2 UTM/WGS84 projection</p></li>
</ul>
<div class="figure">
<img src="fig/Sentinel2_granules.png" alt="" />
<p class="caption">Sentinel 2 Granules</p>
</div>
</div>
<div id="acquiring-sentinel-2-data" class="section level2">
<h2>Acquiring Sentinel-2 data</h2>
<ul>
<li><p>Create a User-Account at the <a href="https://scihub.copernicus.eu/dhus/#/home">Copernicus Open Access Hub</a></p></li>
<li><p>Search for images with these specifications:</p>
<pre><code>Date: XXX

Sensor: Sentinel-2

Producttype: Surface Reflectance (Level 2A, S2MSI2A) 

Cloud cover: max. 20%

Region: greater area of Berlin</code></pre></li>
<li><p>How many images are available for these specifications? download this image:</p></li>
</ul>
<p>Granule: XXX</p>
<p>Date: XXX</p>
</div>
<div id="pre-processing" class="section level2">
<h2>Pre-processing</h2>
<ul>
<li><p>The downloaded Sentinel-2 image is a .zip-file</p></li>
<li><p>Unzip it and delete the .zip-file</p></li>
<li><p>Take a look at your files</p></li>
</ul>
<div class="figure">
<img src="fig/Sentinel2_filestructure.png" alt="" />
<p class="caption">Sentinel 2 filestructure</p>
</div>
<div id="visualizing-the-sentinel-2-image-with-virtual-raster-builder-in-the-enmap-box" class="section level3">
<h3>Visualizing the Sentinel-2 image with ‘Virtual Raster Builder’ in the EnMAP-Box</h3>
<ul>
<li><p>Goal: the single bands in JPEG2000-format (.jp2) will be merged into a single Multiband-Image in ENVI-format</p></li>
<li><p>Open QGIS and install the ‘Virtual Raster Builder’ plugin</p></li>
<li><p>Open the EnMAP-Box and load ‘S2_Subset_Berlin.shp’ into Data Sources. The shapefile will be used to clip the Sentinel-2 scene to a smaller extend</p></li>
<li><p>Open ‘Virtual Raster Builder’ from the EnMAP-Box. Create a Multiband-Image with the following specifications:</p>
<ul>
<li>Spectral Bands: B2, B3, B4, B5, B6, B7, B8a, B11, B12</li>
<li>Spatial Resolution: 20m (from the ‘R20M’ file)</li>
<li>Spatial Extend: according to the shapefile</li>
<li>Format: ENVI</li>
</ul></li>
</ul>
</div>
<div id="create-vrt-in-den-folien-vom-vorjahr-soll-man-ein-envi-erstellen" class="section level3">
<h3>Create VRT (in den Folien vom Vorjahr soll man ein ENVI erstellen…)</h3>
</div>
<div id="amend-metadata" class="section level3">
<h3>Amend metadata</h3>
<ul>
<li><p>Visualize the Multiband Sentinel-2 Image in the EnMAP-Box with the band combination R = 8a (nIR), G = 4 (red), B = 3 (green).</p></li>
<li><p>Take a look at the .hdr file. Which metainformation is missing ?</p></li>
<li><p>Delete the edited Sentinel-2 image from the Data Source Panel. Also delete the .aux-file and .vrt-file from apple finder / windows explorer</p></li>
<li><p>Add the wavelengths of the single bands and the unit for the wavelengths in the .hdr file (metadata). Research the unit and the extend of the applied Sentinel-2 wavelengths.</p></li>
<li><p>Reload the Sentinel-2 image into the Data Source Panel. The wavelengths should now be displayed on the x-axis when visualizing at image spectra. Now you can compare spectra from different Sensors.</p></li>
</ul>
</div>
<div id="compare-s2-hymap" class="section level3">
<h3>Compare S2 &amp; HyMap</h3>
<p>part 1 - spatial resolution</p>
<ul>
<li><p>Visualize the Sentinel-2 image and the HyMap image from last week in a RGB bandcombination that is suited for comparison. In order to do that open the images in two separate MapViews and link them (spatialy + zoom)</p></li>
<li><p>Compare both images visually and describe the effects on image details due to the different spatial resolution (20 m vs. 3.6 m).</p></li>
<li><p>Choose one surface as example for each of these classes: impervious- build up, impervious- not build up, grass/lawn, trees, soil, water.</p></li>
<li><p>Take a screenshot from each example.</p></li>
</ul>
</div>
<div id="compare-s2-hymap-1" class="section level3">
<h3>Compare S2 &amp; HyMap</h3>
<p>part 2 - spectral resolution</p>
<ul>
<li><p>Restart QGIS and EnMAP-Box. Display the Sentinel-2 image and the HyMap image in a suited RGB band combination (Wozu ist der Neustart notwendig ?)</p></li>
<li><p>Visualize spectra of the same surface in the Sentinel-2 and in the HyMAP image (9 vs. 111 spectral bands).</p></li>
<li><p>Try to choose a ‘pure’ surface (no mixtures) which is also stable in temporal terms (unchanged over time).</p></li>
<li><p>Do this for the classes mentioned above and add a description and a screenshot.</p></li>
<li><p><strong>Assignment:</strong> please upload the comparison (spatial and spectral) of the Sentinel-2 and the HyMap image as pdf to moodle.</p></li>
</ul>
<div class="figure">
<img src="fig/homework_example.png" alt="" />
<p class="caption">assignment example</p>
</div>
<hr />
</div>
</div>
</div>
<div id="vegetation-properties-spectral-indices" class="section level1">
<h1>Vegetation properties &amp; spectral indices</h1>
<p><img src="fig/spectral_resolution_comparison.png" /></p>
<div id="normalized-difference-vegetation-index-ndvi" class="section level2">
<h2>Normalized Difference Vegetation Index (NDVI)</h2>
<ul>
<li><p>The derivation of vegetation indicies or similar variables is based on feature extraction</p></li>
<li><p>NDVI the one of the most common vegeation indicies</p></li>
<li><p>It represents the difference between red and nIR reflectance. This difference is strongly prounounced with photosynthetically active vegetation. (Sollte man wahrscheinlich nochmal umschreiben)</p></li>
<li><p>The NDVI displayes this difference within a normalized value (between -1 and 1) for each pixel.</p></li>
</ul>
<p><span class="math display">\[NDVI = (ρnIR- ρred) / (ρnIR+ ρred)\]</span></p>
<ul>
<li><p>e.g. for Sentinel-2 data use reflectance from bands nIR = 865 nm and red = 665 nm for calculating the NDVI.</p></li>
<li><p>The calculation of the NDVI results in a singleband grayscale image which can be saved as a new file.</p></li>
</ul>
</div>
<div id="part-1-calculating-the-normalized-difference-vegetation-index-ndvi-for-sentinel-2-data" class="section level2">
<h2>Part 1: Calculating the Normalized Difference Vegetation Index (NDVI) for Sentinel-2 data</h2>
<ul>
<li><p>Open the EnMAP-Box and display the Sentinel-2 image (20 m, 9 spectral bands, subset Berlin, DATE: XXX) from last week in a RGB bandcombination of your choice.</p></li>
<li><p>via ‘Applications’ start the ‘imageMath Calculator’ and calculate the NDVI.</p>
<pre><code>1. specify the the input image    -&gt; S2_20m = [select Sentinel-2 image]

2. define bands nIR [865 nm] and  -&gt; red    = float32(S2_20m[2])
   red [665 nm] as variable       -&gt; nIR    = float32(S2_20m[6])  

3. provide the NDVI formular      -&gt; NDVI   = (nIR - red)/(nIR + red)

4. specify the output image       -&gt; NDVI   = [filepath and name of the NDVI image]</code></pre></li>
<li><p>Run the function and open the singleband grayscale image in a new Map View</p></li>
</ul>
</div>
<div id="part-2-discussion-of-the-ndvi" class="section level2">
<h2>Part 2: Discussion of the NDVI</h2>
<ul>
<li><p>Take a look at the NDVI-Pixelvalues and create a NDVI image-histogram (Tools ‘ImageStatistics’)</p></li>
<li><p>Which value range take pixels in the NDVI image ?</p></li>
<li><p>Note a representative NDVI value for these surfaces: water, asphalt, decidous forest, open soil.</p></li>
<li><p>Also, note the corresponding refectance values in the red and nIR band from the original image. How can the values be explained, concerning the spectral properties of the surfaces?</p></li>
<li><p>Under what cirumstances (relation red to nIR) can NDVI values of 0; 1; -1 be created (in theory)? Please note one pair of values (red and nIR) for each of these NDVI values.</p></li>
</ul>
</div>
<div id="part-3-visualizing-of-ndvi-classes" class="section level2">
<h2>part 3: Visualizing of NDVI classes</h2>
<ul>
<li>classify the NDVI image through the style menu within the layer properties. Try to display three surfaces: water, impervious/soil and vegetation.</li>
</ul>
<p><img src="fig/NDVI_classification_properties.png" /></p>
</div>
<div id="assignment-part-1-correlation-of-ndvi-and-imperviousness" class="section level2">
<h2>Assignment part 1: Correlation of NDVI and Imperviousness</h2>
<ul>
<li><p>Open the image ‘copernius_imperviousness_2015_berlin.bsq’ in a second Map Window and link it to the NDVI image.</p></li>
<li><p>Inform yourself about the origin of the layer: (<a href="https://land.copernicus.eu/pan-european/high-resolution-layers/imperviousness" class="uri">https://land.copernicus.eu/pan-european/high-resolution-layers/imperviousness</a>)</p></li>
<li><p>Gather NDVI values of 20 surfaces (zu viele, 10 würden reichen) in a table. Make sure to cover a wide range of values (e.g. -0.2 to 1).</p></li>
<li><p>Create a scatterplot that shows the correlation between NDVI and imperviousness. Use a software of your choice; prefarably R.</p></li>
<li><p>Describe and discuss the scatterplot in bullitpoints.</p></li>
</ul>
</div>
<div id="assignment-part-2-temporal-variation-of-the-ndvi" class="section level2">
<h2>Assignment part 2: Temporal Variation of the NDVI</h2>
<ul>
<li><p>Calculate another NDVI image from the provided Sentinel-2 image taken in winter (date XXX). Use the ‘imageMath Calculator’.</p>
<p>-&gt; Sentinel_2_T33UUU_20190216_20m_9bands_subset_berlin.bsq</p></li>
<li><p>Then calculate a difference-image for summer and winter NDVI.</p>
<p>-&gt; NDVI 27. Juli 2019 – NDVI 16. Februar 2019 DATES: XXX</p></li>
<li><p>Create the histogram of the difference-image and briefly discuss the distribution</p></li>
<li><p>Display the difference-image in a suited Visualisation; e.g. discrete classes, colour gradient from high negative to high positive differences.</p></li>
<li><p>Discuss the resulting Map in bullitpoints concerning these surfaces: impervious (buildings, and non build-up), agriculture, forest, water.</p></li>
<li><p><strong>Assignment:</strong> Please upload the results of the comparison of NDVI and imperviousness (part 1, plot and discussion) and the temporal variation of NDVI (part 2, histogram, map + legend, discussion) as pdf to moodle.</p></li>
</ul>
<p>Berechnen Sie das Histogramm des NDVI-Differenzbildes und diskutieren Sie die Verteilung stichpunktartig.</p>
<p>Stellen Sie das NDVI-Differenzbild mit einer sinnvollen Visualisierung dar, z.B. einer diskrete Klassenunterteilung, oder einem Farbgradienten von hohen negativen bis zu hohen positiven Differenzen. Diskutieren Sie die Karte stichpunktartig bzgl. folgender Oberflächen: Versiegelte Flächen (Gebäude &amp; unbebaut), Landwirtschaft, Wald, Wasser Bitte laden Sie die Ergebnisse des Vergleiches NDVI und Versieglung (Teil 1, Plot, Diskussion) und der temporalen Variation des NDVI (Teil 2; Histogramm, Karte + Legende, Diskussion) als PDF in Moodle hoch.</p>
<hr />
</div>
</div>
<div id="image-classification" class="section level1">
<h1>Image classification</h1>
<hr />
</div>
<div id="random-forest" class="section level1">
<h1>Random forest</h1>
<hr />
</div>
<div id="accuracy-assessment" class="section level1">
<h1>Accuracy assessment</h1>
<hr />
</div>
<div id="sentinel-2-time-series" class="section level1">
<h1>Sentinel-2 time series</h1>
<hr />
</div>
<div id="modis-time-series" class="section level1">
<h1>MODIS time series</h1>
<hr />
</div>
<div id="case-studies-change-detection" class="section level1">
<h1>Case studies: Change detection</h1>
<hr />
</div>

    </div>
    <div class="col-xs-2">
        </div>
  </div>
  </div>
  </div>
  <div class="row">
    </div>
  </div>

<script>
$(document).ready(function () {
  // add bootstrap table styles to pandoc tables
  $('tr.header').parent('thead').parent('table').addClass('table table-striped table-hover');

    var images = $('.pages img');
  images.filter(function() {
      if ($(this).parent().attr("class") == "figure") {
          return(false)
      } else {
          return(true);
      }
  }).wrap("<div class='figure'></div>");
  images.addClass("image-thumb").wrap("<div class='panel-body'></div>");
  $('.figure p.caption').wrap("<div class='panel-footer'></div>");
  $('.figure').addClass('panel panel-default');
  
    $('.pages img')
 	  .addClass("image-lb");
  $('.pages').magnificPopup({
	      type:'image',
	      closeOnContentClick: false,
	      closeBtnInside: false,
        delegate: 'img',
	      gallery: {enabled: false },
          removalDelay: 500,
          callbacks: {
              beforeOpen: function() {
                // just a hack that adds mfp-anim class to markup
                this.st.image.markup = this.st.image.markup.replace('mfp-figure', 'mfp-figure mfp-with-anim');
              }
          },
          mainClass: 'mfp-move-from-top',
	      image: {
	        verticalFit: true,
            titleSrc: 'alt'
	      }
 	    });
 	
    
    $('#toc ul li').first().addClass("active");
    $('#toc ul li').attr("data-target", function() {
        return($(this).children("a").attr("href"));
    })
    $('body .section.level1').first().addClass("active");
    $('body .section.level1').not('.active').hide();
    
    $('#toc a[href*="#"]').click(function() {

      var id = $(this).attr("href");
      if (id === "#") return;
      if (id.substring(0, 8) === "#dyntab-") return;
      toggle_page(id);

      // Menu
      var menu_entry = $(".menu li[data-target='"+id+"']");
      menu_entry.addClass("active");
      $(".menu li").not(menu_entry).removeClass("active"); 
      

    });

    function toggle_page(id) {
      $(".page").not(page).removeClass("active").hide();
      window.page = id;
      var page = $(window.page);
      window.location.hash = window.page;
      //$(this).addClass("active");

      page.show();

      var totop = setInterval(function () {
        $(".pages").animate({scrollTop: 0}, 0);
      }, 10);

      setTimeout(function () {
        page.addClass("active");
        setTimeout(function () {
          clearInterval(totop);
        }, 1000);
      }, 100);

      window.dispatchEvent(new Event('resize'));

    }


    $(".menu li").click(function () {

      toggle_page($(this).data("target"));

      // Menu
      if (!$(this).data("target")) return;
      if ($(this).is(".active")) return;
      $(".menu li").not($(this)).removeClass("active");
      $(this).addClass("active");

    });
  
    


    window.page = window.location.hash;
    if (window.page != "") {
      $(".menu").find("li[data-target=" + window.page + "]").trigger("click");
    }

    /* init material bootstrap js */
    $.material.init();
});
</script>




<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
